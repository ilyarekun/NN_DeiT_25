## Vision Transformers (ViTs)


### Project 19: Implementing Data-efficient Image Transformers (DeiT) for Image Classification


1. Title of the Project: 
    Data-efficient Image Transformers (DeiT) for Image Classification

2. Literature Overview: 
    DeiT is a Vision Transformer variant that enhances training efficiency
and performance without requiring extensive datasets. It introduces a teacher-student
distillation approach to improve accuracy. For more details, refer to the paper (["Training
Data-Efficient Image Transformers & Distillation Through Attention"](https://arxiv.org/abs/2012.12877)).


3. Source of the Code: 
    The official implementation of DeiT is available on GitHub: 
[DeiT GitHub Repository](https://github.com/facebookresearch/deit)

5. Dataset Management and Acquisition: 
Utilize the  [CIFAR-100](https://www.kaggle.com/datasets/fedesoriano/cifar100) dataset, which contains 100 classes of images. 
Split the dataset into 70% training, 15% validation, and 15% testing sets
to ensure robust model evaluation.

6. Analytics of the Source Code: 
Develop a flow diagram illustrating the DeiT architecture,
highlighting the distillation token mechanism and the training process. 
This will demonstrate a clear understanding of the model's structure and data flow.

7. Results Analysis: 
Evaluate the model's performance using accuracy metrics 
and present a confusion matrix to analyze classification errors across different classes.

8. Conclusion: 
Prepare a public video presentation detailing the project's objectives,
methodology, results, and individual contributions. 
Recording via Microsoft Teams is recommended, and ensure the video is submitted by the deadline. 
All project team members should speak in the video - there is no time limitation on video. 
Be aware that the video will go public to increase your position among stakeholders in companies.