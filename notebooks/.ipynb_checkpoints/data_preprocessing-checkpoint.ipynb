{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;94m Static hostname:\u001b[0m DGX\n",
      "\u001b[0;94m       Icon name:\u001b[0m computer-server\n",
      "\u001b[0;94m         Chassis:\u001b[0m server üñ≥\n",
      "\u001b[0;94m      Machine ID:\u001b[0m dedf5691225742ff95b33f842b0781cc\n",
      "\u001b[0;94m         Boot ID:\u001b[0m cb04df0ff1774eeda112c63867eeefdd\n",
      "\u001b[0;94mOperating System:\u001b[0m \u001b]8;;https://www.ubuntu.com/\u0007Ubuntu 24.04.2 LTS\u001b]8;;\u0007              \n",
      "\u001b[0;94m          Kernel:\u001b[0m Linux 6.8.0-53-generic\n",
      "\u001b[0;94m    Architecture:\u001b[0m x86-64\n",
      "\u001b[0;94m Hardware Vendor:\u001b[0m NVIDIA\n",
      "\u001b[0;94m  Hardware Model:\u001b[0m DGXA100 920-23687-2530-002\n",
      "\u001b[0;94mFirmware Version:\u001b[0m 1.29\n",
      "\u001b[0;94m   Firmware Date:\u001b[0m Tue 2024-08-06\n",
      "\u001b[0;94m    Firmware Age:\u001b[0m 7month 2w 5d\n"
     ]
    }
   ],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/ir739wb/.cache/kagglehub/datasets/fedesoriano/cifar100/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"fedesoriano/cifar100\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file.txt  meta  test  train\n"
     ]
    }
   ],
   "source": [
    "%ls /home/ir739wb/.cache/kagglehub/datasets/fedesoriano/cifar100/versions/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ir739wb/ilyarekun/nn-lessons'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ir739wb\n"
     ]
    }
   ],
   "source": [
    "%cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34milyarekun\u001b[0m/  \u001b[01;34mminiconda3\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ir739wb/ilyarekun/nn_DeiT_25\n"
     ]
    }
   ],
   "source": [
    "%cd ilyarekun/nn_DeiT_25/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  error.log  jbdeit.slurm  output.log\n",
      "\u001b[0m\u001b[01;34mdata\u001b[0m/      \u001b[01;34mfbkrep\u001b[0m/    \u001b[01;34mnotebooks\u001b[0m/    todo.md\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp -r /home/ir739wb/.cache/kagglehub/datasets/fedesoriano/cifar100/versions/1 ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ir739wb/ilyarekun/nn-lessons'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ir739wb/ilyarekun/nn_DeiT_25\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ir739wb/ilyarekun/nn_DeiT_25/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ train (70%), val (15%), test (15%) –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞ CIFAR-100\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "# –ü—É—Ç—å –∫ —Å–∫–∞—á–∞–Ω–Ω–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É\n",
    "path = \"/home/ir739wb/.cache/kagglehub/datasets/fedesoriano/cifar100/versions/1\"  # –£–∫–∞–∂–∏ —Å–≤–æ–π –ø—É—Ç—å\n",
    "data_pre_path = \"./data/1\"  # –ö—É–¥–∞ —Ç—ã —Å–∫–æ–ø–∏—Ä–æ–≤–∞–ª –¥–∞–Ω–Ω—ã–µ\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π\n",
    "output_dir = \"./cifar100_imagenet_style\"\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤\n",
    "metadata_path = os.path.join(data_pre_path, \"meta\")\n",
    "metadata = unpickle(metadata_path)\n",
    "fine_label_names = [name.decode('utf-8') for name in metadata[b'fine_label_names']]  # 100 –∫–ª–∞—Å—Å–æ–≤\n",
    "\n",
    "# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ train, val –∏ test\n",
    "for label_name in fine_label_names:\n",
    "    os.makedirs(os.path.join(train_dir, label_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, label_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, label_name), exist_ok=True)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "data_train_path = os.path.join(data_pre_path, \"train\")\n",
    "data_train_dict = unpickle(data_train_path)\n",
    "data_train = data_train_dict[b'data']  # (50000, 3072)\n",
    "label_train = np.array(data_train_dict[b'fine_labels'])  # (50000,)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "data_test_path = os.path.join(data_pre_path, \"test\")\n",
    "data_test_dict = unpickle(data_test_path)\n",
    "data_test = data_test_dict[b'data']  # (10000, 3072)\n",
    "label_test = np.array(data_test_dict[b'fine_labels'])  # (10000,)\n",
    "\n",
    "# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "data_all = np.vstack((data_train, data_test))  # (60000, 3072)\n",
    "label_all = np.hstack((label_train, label_test))  # (60000,)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train (70%), val (15%), test (15%) —Å —É—á–µ—Ç–æ–º –∫–ª–∞—Å—Å–æ–≤\n",
    "train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
    "    np.arange(len(label_all)), label_all, test_size=0.3, stratify=label_all, random_state=42\n",
    ")\n",
    "val_idx, test_idx, val_labels, test_labels = train_test_split(\n",
    "    temp_idx, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
    "def save_image(data, label, index, folder):\n",
    "    img_data = data[index].reshape(3, 32, 32).transpose(1, 2, 0)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–∑ (3072,) –≤ (32, 32, 3)\n",
    "    img = Image.fromarray(img_data)\n",
    "    class_name = fine_label_names[label[index]]\n",
    "    img_path = os.path.join(folder, class_name, f\"img{index}.jpeg\")\n",
    "    img.save(img_path)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ train, val, test\n",
    "for idx in train_idx:\n",
    "    save_image(data_all, label_all, idx, train_dir)\n",
    "\n",
    "for idx in val_idx:\n",
    "    save_image(data_all, label_all, idx, val_dir)\n",
    "\n",
    "for idx in test_idx:\n",
    "    save_image(data_all, label_all, idx, test_dir)\n",
    "\n",
    "print(\"–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ train (70%), val (15%), test (15%) –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ train: 42000\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ val: 9000\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ val: 9000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# –ü—É—Ç—å –∫ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
    "base_path = \"/home/ir739wb/ilyarekun/nn_DeiT_25/cifar100_imagenet_style\"\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ —Ñ–∞–π–ª–æ–≤ –≤ –ø–æ–¥–ø–∞–ø–∫–µ (train –∏–ª–∏ val)\n",
    "def count_files_in_subfolder(subfolder):\n",
    "    subfolder_path = os.path.join(base_path, subfolder)\n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(subfolder_path):\n",
    "        total_files += len(files)\n",
    "    return total_files\n",
    "\n",
    "# –ü–æ–¥—Å—á—ë—Ç —Ñ–∞–π–ª–æ–≤ –≤ train –∏ val\n",
    "train_files = count_files_in_subfolder(\"train\")\n",
    "val_files = count_files_in_subfolder(\"val\")\n",
    "test_files = count_files_in_subfolder(\"test\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ train: {train_files}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ val: {val_files}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ val: {test_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
