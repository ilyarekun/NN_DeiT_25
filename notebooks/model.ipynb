{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/ir739wb/ilyarekun/nn_DeiT_25/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-680b5566-f66c-da58-c59b-1a9e054d807f)\n",
      "GPU 1: NVIDIA A100-SXM4-40GB (UUID: GPU-72420bd6-f473-9783-fc6a-5894ccc331f2)\n",
      "Using device: cuda, GPU count: 2\n",
      "Using DataParallel for multi-GPU training\n",
      "Epoch 1/100, Train Loss: 3.6672, Val Loss: 2.3850, Val Acc: 43.48%, Precision: 0.4380, Recall: 0.4348, F1: 0.3982\n",
      "Epoch 2/100, Train Loss: 2.3699, Val Loss: 1.8381, Val Acc: 54.76%, Precision: 0.5002, Recall: 0.4912, F1: 0.4704\n",
      "Epoch 3/100, Train Loss: 1.9601, Val Loss: 1.6842, Val Acc: 57.00%, Precision: 0.5177, Recall: 0.5174, F1: 0.5027\n",
      "Epoch 4/100, Train Loss: 1.7377, Val Loss: 1.5841, Val Acc: 59.39%, Precision: 0.5361, Recall: 0.5366, F1: 0.5250\n",
      "Epoch 5/100, Train Loss: 1.6196, Val Loss: 1.5828, Val Acc: 60.39%, Precision: 0.5504, Recall: 0.5500, F1: 0.5404\n",
      "Epoch 6/100, Train Loss: 1.5101, Val Loss: 1.5166, Val Acc: 61.52%, Precision: 0.5591, Recall: 0.5609, F1: 0.5528\n",
      "Epoch 7/100, Train Loss: 1.4173, Val Loss: 1.5540, Val Acc: 60.74%, Precision: 0.5650, Recall: 0.5675, F1: 0.5603\n",
      "Epoch 8/100, Train Loss: 1.3520, Val Loss: 1.4491, Val Acc: 62.94%, Precision: 0.5718, Recall: 0.5753, F1: 0.5682\n",
      "Epoch 9/100, Train Loss: 1.1303, Val Loss: 1.3554, Val Acc: 65.24%, Precision: 0.5802, Recall: 0.5839, F1: 0.5774\n",
      "Epoch 10/100, Train Loss: 1.0443, Val Loss: 1.3653, Val Acc: 65.20%, Precision: 0.5865, Recall: 0.5907, F1: 0.5845\n",
      "Epoch 11/100, Train Loss: 1.0009, Val Loss: 1.3776, Val Acc: 65.12%, Precision: 0.5921, Recall: 0.5962, F1: 0.5904\n",
      "Epoch 12/100, Train Loss: 0.9420, Val Loss: 1.3220, Val Acc: 65.86%, Precision: 0.5969, Recall: 0.6014, F1: 0.5957\n",
      "Epoch 13/100, Train Loss: 0.8907, Val Loss: 1.3753, Val Acc: 65.46%, Precision: 0.6014, Recall: 0.6055, F1: 0.6002\n",
      "Epoch 14/100, Train Loss: 0.8629, Val Loss: 1.3474, Val Acc: 66.51%, Precision: 0.6059, Recall: 0.6097, F1: 0.6047\n",
      "Epoch 15/100, Train Loss: 0.8207, Val Loss: 1.3467, Val Acc: 66.34%, Precision: 0.6097, Recall: 0.6133, F1: 0.6086\n",
      "Epoch 16/100, Train Loss: 0.7853, Val Loss: 1.3599, Val Acc: 66.08%, Precision: 0.6127, Recall: 0.6163, F1: 0.6116\n",
      "Epoch 17/100, Train Loss: 0.6448, Val Loss: 1.2682, Val Acc: 68.14%, Precision: 0.6167, Recall: 0.6201, F1: 0.6157\n",
      "Epoch 18/100, Train Loss: 0.5808, Val Loss: 1.2873, Val Acc: 67.98%, Precision: 0.6202, Recall: 0.6234, F1: 0.6192\n",
      "Epoch 19/100, Train Loss: 0.5619, Val Loss: 1.3104, Val Acc: 67.74%, Precision: 0.6231, Recall: 0.6263, F1: 0.6222\n",
      "Epoch 20/100, Train Loss: 0.5443, Val Loss: 1.3246, Val Acc: 67.32%, Precision: 0.6254, Recall: 0.6286, F1: 0.6246\n",
      "Epoch 21/100, Train Loss: 0.5213, Val Loss: 1.3322, Val Acc: 67.44%, Precision: 0.6276, Recall: 0.6308, F1: 0.6268\n",
      "Epoch 22/100, Train Loss: 0.5026, Val Loss: 1.3366, Val Acc: 67.86%, Precision: 0.6299, Recall: 0.6330, F1: 0.6292\n",
      "Epoch 23/100, Train Loss: 0.5000, Val Loss: 1.3384, Val Acc: 67.71%, Precision: 0.6319, Recall: 0.6349, F1: 0.6313\n",
      "Epoch 24/100, Train Loss: 0.4824, Val Loss: 1.3289, Val Acc: 68.03%, Precision: 0.6338, Recall: 0.6368, F1: 0.6333\n",
      "Epoch 25/100, Train Loss: 0.3971, Val Loss: 1.2547, Val Acc: 69.42%, Precision: 0.6361, Recall: 0.6391, F1: 0.6357\n",
      "Epoch 26/100, Train Loss: 0.3654, Val Loss: 1.2832, Val Acc: 68.52%, Precision: 0.6380, Recall: 0.6409, F1: 0.6376\n",
      "Epoch 27/100, Train Loss: 0.3476, Val Loss: 1.2793, Val Acc: 69.02%, Precision: 0.6400, Recall: 0.6427, F1: 0.6396\n",
      "Epoch 28/100, Train Loss: 0.3376, Val Loss: 1.2922, Val Acc: 68.86%, Precision: 0.6416, Recall: 0.6443, F1: 0.6413\n",
      "Epoch 29/100, Train Loss: 0.3337, Val Loss: 1.3216, Val Acc: 68.18%, Precision: 0.6430, Recall: 0.6456, F1: 0.6427\n",
      "Epoch 30/100, Train Loss: 0.3401, Val Loss: 1.3342, Val Acc: 68.07%, Precision: 0.6442, Recall: 0.6468, F1: 0.6440\n",
      "Epoch 31/100, Train Loss: 0.3276, Val Loss: 1.3195, Val Acc: 67.91%, Precision: 0.6454, Recall: 0.6478, F1: 0.6451\n",
      "Epoch 32/100, Train Loss: 0.3346, Val Loss: 1.3268, Val Acc: 68.63%, Precision: 0.6468, Recall: 0.6490, F1: 0.6465\n",
      "Epoch 33/100, Train Loss: 0.2737, Val Loss: 1.2847, Val Acc: 69.87%, Precision: 0.6484, Recall: 0.6505, F1: 0.6480\n",
      "Epoch 34/100, Train Loss: 0.2587, Val Loss: 1.2895, Val Acc: 69.09%, Precision: 0.6495, Recall: 0.6517, F1: 0.6492\n",
      "Epoch 35/100, Train Loss: 0.2518, Val Loss: 1.2898, Val Acc: 69.13%, Precision: 0.6507, Recall: 0.6528, F1: 0.6504\n",
      "Epoch 36/100, Train Loss: 0.2376, Val Loss: 1.2923, Val Acc: 69.03%, Precision: 0.6518, Recall: 0.6539, F1: 0.6515\n",
      "Epoch 37/100, Train Loss: 0.2375, Val Loss: 1.2820, Val Acc: 69.18%, Precision: 0.6530, Recall: 0.6549, F1: 0.6526\n",
      "Epoch 38/100, Train Loss: 0.2336, Val Loss: 1.3238, Val Acc: 68.71%, Precision: 0.6539, Recall: 0.6558, F1: 0.6535\n",
      "Epoch 39/100, Train Loss: 0.2358, Val Loss: 1.3006, Val Acc: 69.14%, Precision: 0.6548, Recall: 0.6567, F1: 0.6544\n",
      "Epoch 40/100, Train Loss: 0.2298, Val Loss: 1.3175, Val Acc: 69.42%, Precision: 0.6559, Recall: 0.6576, F1: 0.6555\n",
      "Epoch 41/100, Train Loss: 0.2104, Val Loss: 1.2889, Val Acc: 69.38%, Precision: 0.6569, Recall: 0.6585, F1: 0.6564\n",
      "Epoch 42/100, Train Loss: 0.1995, Val Loss: 1.2907, Val Acc: 69.16%, Precision: 0.6577, Recall: 0.6593, F1: 0.6572\n",
      "Epoch 43/100, Train Loss: 0.1932, Val Loss: 1.2987, Val Acc: 69.63%, Precision: 0.6586, Recall: 0.6601, F1: 0.6581\n",
      "Epoch 44/100, Train Loss: 0.1868, Val Loss: 1.2958, Val Acc: 69.72%, Precision: 0.6594, Recall: 0.6610, F1: 0.6590\n",
      "Epoch 45/100, Train Loss: 0.1874, Val Loss: 1.2911, Val Acc: 69.74%, Precision: 0.6603, Recall: 0.6618, F1: 0.6598\n",
      "Epoch 46/100, Train Loss: 0.1890, Val Loss: 1.3102, Val Acc: 69.78%, Precision: 0.6611, Recall: 0.6626, F1: 0.6606\n",
      "Epoch 47/100, Train Loss: 0.2007, Val Loss: 1.3106, Val Acc: 69.81%, Precision: 0.6619, Recall: 0.6633, F1: 0.6614\n",
      "Epoch 48/100, Train Loss: 0.1911, Val Loss: 1.2905, Val Acc: 69.60%, Precision: 0.6626, Recall: 0.6640, F1: 0.6621\n",
      "Epoch 49/100, Train Loss: 0.1755, Val Loss: 1.2724, Val Acc: 70.03%, Precision: 0.6634, Recall: 0.6648, F1: 0.6629\n",
      "Epoch 50/100, Train Loss: 0.1661, Val Loss: 1.2719, Val Acc: 70.40%, Precision: 0.6643, Recall: 0.6655, F1: 0.6637\n",
      "Epoch 51/100, Train Loss: 0.1650, Val Loss: 1.2972, Val Acc: 69.77%, Precision: 0.6649, Recall: 0.6662, F1: 0.6644\n",
      "Epoch 52/100, Train Loss: 0.1591, Val Loss: 1.2985, Val Acc: 69.50%, Precision: 0.6655, Recall: 0.6667, F1: 0.6650\n",
      "Epoch 53/100, Train Loss: 0.1591, Val Loss: 1.3127, Val Acc: 69.24%, Precision: 0.6660, Recall: 0.6672, F1: 0.6655\n",
      "Epoch 54/100, Train Loss: 0.1627, Val Loss: 1.2973, Val Acc: 69.48%, Precision: 0.6665, Recall: 0.6677, F1: 0.6660\n",
      "Epoch 55/100, Train Loss: 0.1601, Val Loss: 1.3191, Val Acc: 69.62%, Precision: 0.6671, Recall: 0.6682, F1: 0.6666\n",
      "Epoch 56/100, Train Loss: 0.1614, Val Loss: 1.3123, Val Acc: 69.38%, Precision: 0.6676, Recall: 0.6687, F1: 0.6670\n",
      "Epoch 57/100, Train Loss: 0.1516, Val Loss: 1.3040, Val Acc: 69.72%, Precision: 0.6681, Recall: 0.6692, F1: 0.6676\n",
      "Epoch 58/100, Train Loss: 0.1475, Val Loss: 1.2968, Val Acc: 69.90%, Precision: 0.6686, Recall: 0.6697, F1: 0.6681\n",
      "Epoch 59/100, Train Loss: 0.1476, Val Loss: 1.3014, Val Acc: 69.81%, Precision: 0.6692, Recall: 0.6702, F1: 0.6686\n",
      "Epoch 60/100, Train Loss: 0.1438, Val Loss: 1.3023, Val Acc: 69.88%, Precision: 0.6697, Recall: 0.6707, F1: 0.6691\n",
      "Epoch 61/100, Train Loss: 0.1450, Val Loss: 1.3051, Val Acc: 69.91%, Precision: 0.6702, Recall: 0.6711, F1: 0.6696\n",
      "Epoch 62/100, Train Loss: 0.1458, Val Loss: 1.2858, Val Acc: 69.83%, Precision: 0.6706, Recall: 0.6716, F1: 0.6700\n",
      "Epoch 63/100, Train Loss: 0.1401, Val Loss: 1.2980, Val Acc: 70.40%, Precision: 0.6712, Recall: 0.6721, F1: 0.6706\n",
      "Epoch 64/100, Train Loss: 0.1461, Val Loss: 1.3063, Val Acc: 70.23%, Precision: 0.6717, Recall: 0.6726, F1: 0.6711\n",
      "Epoch 65/100, Train Loss: 0.1387, Val Loss: 1.2994, Val Acc: 69.62%, Precision: 0.6721, Recall: 0.6729, F1: 0.6714\n",
      "Epoch 66/100, Train Loss: 0.1365, Val Loss: 1.2866, Val Acc: 70.21%, Precision: 0.6725, Recall: 0.6734, F1: 0.6719\n",
      "Epoch 67/100, Train Loss: 0.1346, Val Loss: 1.2944, Val Acc: 70.37%, Precision: 0.6730, Recall: 0.6738, F1: 0.6724\n",
      "Epoch 68/100, Train Loss: 0.1310, Val Loss: 1.3053, Val Acc: 69.99%, Precision: 0.6734, Recall: 0.6742, F1: 0.6728\n",
      "Epoch 69/100, Train Loss: 0.1337, Val Loss: 1.2923, Val Acc: 69.87%, Precision: 0.6738, Recall: 0.6746, F1: 0.6731\n",
      "Epoch 70/100, Train Loss: 0.1299, Val Loss: 1.2724, Val Acc: 70.56%, Precision: 0.6742, Recall: 0.6750, F1: 0.6736\n",
      "Epoch 71/100, Train Loss: 0.1318, Val Loss: 1.2806, Val Acc: 70.53%, Precision: 0.6747, Recall: 0.6754, F1: 0.6740\n",
      "Epoch 72/100, Train Loss: 0.1306, Val Loss: 1.2805, Val Acc: 70.34%, Precision: 0.6751, Recall: 0.6758, F1: 0.6744\n",
      "Epoch 73/100, Train Loss: 0.1261, Val Loss: 1.2967, Val Acc: 70.22%, Precision: 0.6755, Recall: 0.6762, F1: 0.6748\n",
      "Epoch 74/100, Train Loss: 0.1298, Val Loss: 1.2930, Val Acc: 70.37%, Precision: 0.6760, Recall: 0.6765, F1: 0.6752\n",
      "Epoch 75/100, Train Loss: 0.1276, Val Loss: 1.2960, Val Acc: 70.11%, Precision: 0.6763, Recall: 0.6769, F1: 0.6756\n",
      "Epoch 76/100, Train Loss: 0.1259, Val Loss: 1.2955, Val Acc: 70.24%, Precision: 0.6766, Recall: 0.6772, F1: 0.6759\n",
      "Epoch 77/100, Train Loss: 0.1263, Val Loss: 1.3088, Val Acc: 70.21%, Precision: 0.6770, Recall: 0.6775, F1: 0.6763\n",
      "Epoch 78/100, Train Loss: 0.1246, Val Loss: 1.2755, Val Acc: 70.44%, Precision: 0.6774, Recall: 0.6779, F1: 0.6766\n",
      "Epoch 79/100, Train Loss: 0.1262, Val Loss: 1.3088, Val Acc: 70.06%, Precision: 0.6777, Recall: 0.6782, F1: 0.6769\n",
      "Epoch 80/100, Train Loss: 0.1267, Val Loss: 1.2906, Val Acc: 70.56%, Precision: 0.6780, Recall: 0.6785, F1: 0.6773\n",
      "Epoch 81/100, Train Loss: 0.1257, Val Loss: 1.2895, Val Acc: 70.21%, Precision: 0.6783, Recall: 0.6788, F1: 0.6776\n",
      "Epoch 82/100, Train Loss: 0.1236, Val Loss: 1.3012, Val Acc: 70.43%, Precision: 0.6787, Recall: 0.6791, F1: 0.6779\n",
      "Epoch 83/100, Train Loss: 0.1220, Val Loss: 1.2997, Val Acc: 70.32%, Precision: 0.6790, Recall: 0.6794, F1: 0.6782\n",
      "Epoch 84/100, Train Loss: 0.1243, Val Loss: 1.2802, Val Acc: 70.61%, Precision: 0.6794, Recall: 0.6797, F1: 0.6785\n",
      "Epoch 85/100, Train Loss: 0.1207, Val Loss: 1.2809, Val Acc: 70.38%, Precision: 0.6797, Recall: 0.6800, F1: 0.6788\n",
      "Epoch 86/100, Train Loss: 0.1233, Val Loss: 1.2903, Val Acc: 70.71%, Precision: 0.6800, Recall: 0.6803, F1: 0.6792\n",
      "Epoch 87/100, Train Loss: 0.1197, Val Loss: 1.3040, Val Acc: 70.20%, Precision: 0.6803, Recall: 0.6806, F1: 0.6794\n",
      "Epoch 88/100, Train Loss: 0.1201, Val Loss: 1.2985, Val Acc: 70.34%, Precision: 0.6806, Recall: 0.6808, F1: 0.6797\n",
      "Epoch 89/100, Train Loss: 0.1207, Val Loss: 1.2814, Val Acc: 70.22%, Precision: 0.6808, Recall: 0.6811, F1: 0.6800\n",
      "Epoch 90/100, Train Loss: 0.1207, Val Loss: 1.3068, Val Acc: 70.51%, Precision: 0.6811, Recall: 0.6813, F1: 0.6802\n",
      "Epoch 91/100, Train Loss: 0.1176, Val Loss: 1.3008, Val Acc: 70.36%, Precision: 0.6814, Recall: 0.6816, F1: 0.6805\n",
      "Epoch 92/100, Train Loss: 0.1206, Val Loss: 1.2776, Val Acc: 70.36%, Precision: 0.6817, Recall: 0.6818, F1: 0.6808\n",
      "Epoch 93/100, Train Loss: 0.1188, Val Loss: 1.3025, Val Acc: 70.43%, Precision: 0.6819, Recall: 0.6821, F1: 0.6810\n",
      "Epoch 94/100, Train Loss: 0.1194, Val Loss: 1.3053, Val Acc: 70.11%, Precision: 0.6822, Recall: 0.6823, F1: 0.6812\n",
      "Epoch 95/100, Train Loss: 0.1161, Val Loss: 1.3014, Val Acc: 70.39%, Precision: 0.6824, Recall: 0.6825, F1: 0.6814\n",
      "Epoch 96/100, Train Loss: 0.1201, Val Loss: 1.3070, Val Acc: 70.28%, Precision: 0.6826, Recall: 0.6827, F1: 0.6817\n",
      "Epoch 97/100, Train Loss: 0.1179, Val Loss: 1.3188, Val Acc: 69.84%, Precision: 0.6828, Recall: 0.6829, F1: 0.6818\n",
      "Epoch 98/100, Train Loss: 0.1138, Val Loss: 1.3031, Val Acc: 70.29%, Precision: 0.6831, Recall: 0.6831, F1: 0.6821\n",
      "Epoch 99/100, Train Loss: 0.1161, Val Loss: 1.2965, Val Acc: 70.41%, Precision: 0.6833, Recall: 0.6833, F1: 0.6823\n",
      "Epoch 100/100, Train Loss: 0.1157, Val Loss: 1.2816, Val Acc: 71.14%, Precision: 0.6836, Recall: 0.6836, F1: 0.6826\n",
      "Model weights saved to 'teacher_regnety160_cifar100.pth'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "from torchvision.models import regnet_y_16gf, RegNet_Y_16GF_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,garbage_collection_threshold:0.8\"\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n",
    "\n",
    "# Проверка доступных GPU\n",
    "import subprocess\n",
    "subprocess.run([\"nvidia-smi\", \"-L\"])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}, GPU count: {torch.cuda.device_count()}\")\n",
    "\n",
    "data_path = \"/home/ir739wb/ilyarekun/nn_DeiT_25/cifar100_imagenet_style\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.15),\n",
    "    transforms.RandomVerticalFlip(p=0.15),\n",
    "    transforms.RandomRotation(30), \n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_path, \"train\"), transform=transform)\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_path, \"val\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "# Загружаем предобученную модель RegNetY-16GF\n",
    "teacher_model = models.regnet_y_16gf(weights=RegNet_Y_16GF_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Модифицируем последний слой (fc) на Sequential с Dropout и Linear\n",
    "in_features = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Sequential(\n",
    "    nn.Linear(in_features, 100),\n",
    "    nn.Dropout(p=0.6),\n",
    "    nn.Linear(100, 100)\n",
    ")\n",
    "\n",
    "\"\"\" # Замораживаем все параметры модели\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Размораживаем последние слои: например, trunk_output.block4 и fc\n",
    "for param in teacher_model.trunk_output.block4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in teacher_model.fc.parameters():\n",
    "    param.requires_grad = True \"\"\"\n",
    "\n",
    "# Переносим модель на устройство\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "# Используем DataParallel, если доступно несколько GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using DataParallel for multi-GPU training\")\n",
    "    teacher_model = nn.DataParallel(teacher_model)\n",
    "\n",
    "# Оптимизатор: оптимизируем только размороженные параметры\n",
    "optimizer = optim.Adam(teacher_model.parameters(), lr=0.00005, weight_decay=1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Планировщик скорости обучения\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.7)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1s = []\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        accuracy = 100 * correct / total\n",
    "        val_accuracies.append(accuracy)\n",
    "        precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
    "        val_precisions.append(precision)\n",
    "        val_recalls.append(recall)\n",
    "        val_f1s.append(f1)\n",
    "        \n",
    "        str_res=f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {accuracy:.2f}%, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\"\n",
    "        print(str_res)\n",
    "        with open('results.txt', 'a') as f:\n",
    "            f.write(str_res)\n",
    "        \n",
    "        scheduler.step()  # Обновление скорости обучения\n",
    "        \n",
    "train_model(teacher_model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=100)\n",
    "\n",
    "torch.save(teacher_model.state_dict(), 'teacher_regnety160_cifar100.pth')\n",
    "#torch.save({'model': teacher_model.state_dict()}, 'teacher_regnety160_cifar100.pth')\n",
    "\n",
    "print(\"Model weights saved to 'teacher_regnety160_cifar100.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, val_losses, label='Val Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_vs_epoch.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, val_accuracies, label='Val Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Validation Accuracy vs Epoch\")\n",
    "plt.legend()\n",
    "plt.savefig(\"accuracy_vs_epoch.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, val_precisions, label='Precision')\n",
    "plt.plot(epochs, val_recalls, label='Recall')\n",
    "plt.plot(epochs, val_f1s, label='F1 Score')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision, Recall, F1 vs Epoch\")\n",
    "plt.legend()\n",
    "plt.savefig(\"metrics_vs_epoch.png\")\n",
    "plt.show()\n",
    "\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.run([\"nvidia-smi\", \"-L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 0, NVIDIA A100-SXM4-40GB, GPU-04d2a6bb-264f-6b50-a917-1effa8949810\n",
    "1, NVIDIA A100-SXM4-40GB, GPU-ff3ba929-da03-8441-6ab6-0ad20ecbac5f\n",
    "2, NVIDIA A100-SXM4-40GB, GPU-a3c4b7d3-2308-0714-9328-ffe9888b564c\n",
    "3, NVIDIA A100-SXM4-40GB, GPU-680b5566-f66c-da58-c59b-1a9e054d807f\n",
    "4, NVIDIA A100-SXM4-40GB, GPU-72420bd6-f473-9783-fc6a-5894ccc331f2\n",
    "5, NVIDIA A100-SXM4-40GB, GPU-2beb933a-6d58-ad8e-f216-de8e19ff4ecc\n",
    "6, NVIDIA A100-SXM4-40GB, GPU-e000602e-d7c7-889e-303d-774fc518edb2\n",
    "7, NVIDIA A100-SXM4-40GB, GPU-5c73ff1d-c5d0-f175-0241-c80dc2a3b970\n",
    "(myenv) ir739wb@DGX:~/ilyarekun/nn_DeiT_25$  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch\n",
    "\n",
    "# Путь к файлу\n",
    "checkpoint_path = \"/home/ir739wb/ilyarekun/nn_DeiT_25/cifar100_imagenet_style/teacher_regnety160_cifar100.pth\"\n",
    "\n",
    "# Загружаем контрольную точку\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "# Проверяем, что содержится в контрольной точке\n",
    "print(\"Ключи в контрольной точке:\", checkpoint.keys())\n",
    "\n",
    "# Предполагаем, что 'model' — ключ для state_dict (может отличаться, проверьте вывод выше)\n",
    "state_dict = checkpoint if 'model' not in checkpoint else checkpoint['model']\n",
    "\n",
    "# Выводим первые несколько ключей state_dict\n",
    "print(\"\\nПервые 10 ключей в state_dict:\")\n",
    "for i, key in enumerate(state_dict.keys()):\n",
    "    if i < 10:\n",
    "        print(f\"  {key}\")\n",
    "\n",
    "# Проверяем последний слой (обычно это 'head.fc.weight' или 'fc.weight')\n",
    "for key in state_dict.keys():\n",
    "    if 'fc.weight' in key or 'linear.weight' in key:\n",
    "        num_classes = state_dict[key].shape[0]\n",
    "        print(f\"\\nНайден последний слой: {key}\")\n",
    "        print(f\"Количество классов: {num_classes}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"\\nПоследний слой не найден (возможно, нестандартное имя).\")\n",
    "\n",
    "# Выводим общее количество параметров\n",
    "total_params = sum(p.numel() for p in state_dict.values())\n",
    "print(f\"\\nОбщее количество параметров: {total_params}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Путь к исходной контрольной точке\n",
    "checkpoint_path = \"/home/ir739wb/ilyarekun/nn_DeiT_25/cifar100_imagenet_style/teacher_regnety160_cifar100.pth\"\n",
    "\n",
    "# Загружаем контрольную точку\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "state_dict = checkpoint['model']\n",
    "\n",
    "# Новый state_dict для адаптации\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "# Параметры для адаптации\n",
    "new_num_classes = 100  # Укажите нужное количество классов\n",
    "remove_prefix = \"base_model.\"  # Префикс, который нужно убрать\n",
    "\n",
    "# Обрабатываем каждый ключ\n",
    "for key, value in state_dict.items():\n",
    "    # Убираем префикс \"base_model.\"\n",
    "    new_key = key.replace(remove_prefix, \"\")\n",
    "    \n",
    "    # Адаптируем последний слой\n",
    "    if new_key == \"fc.weight\":\n",
    "        old_num_classes = value.shape[0]  # 100\n",
    "        print(f\"Старое количество классов: {old_num_classes}, Новое: {new_num_classes}\")\n",
    "        if old_num_classes != new_num_classes:\n",
    "            # Создаём новый весовой тензор с нужным количеством классов\n",
    "            new_weight = torch.randn(new_num_classes, value.shape[1])  # Случайная инициализация\n",
    "            new_state_dict[new_key] = new_weight\n",
    "            print(f\"Заменён вес {new_key} с {value.shape} на {new_weight.shape}\")\n",
    "        else:\n",
    "            new_state_dict[new_key] = value\n",
    "    elif new_key == \"fc.bias\":\n",
    "        old_num_classes = value.shape[0]  # 100\n",
    "        if old_num_classes != new_num_classes:\n",
    "            # Создаём новый bias с нужным количеством классов\n",
    "            new_bias = torch.randn(new_num_classes)  # Случайная инициализация\n",
    "            new_state_dict[new_key] = new_bias\n",
    "            print(f\"Заменён bias {new_key} с {value.shape} на {new_bias.shape}\")\n",
    "        else:\n",
    "            new_state_dict[new_key] = value\n",
    "    else:\n",
    "        # Копируем остальные параметры без изменений\n",
    "        new_state_dict[new_key] = value\n",
    "\n",
    "# Обновляем контрольную точку\n",
    "checkpoint['model'] = new_state_dict\n",
    "\n",
    "# Сохраняем адаптированную контрольную точку\n",
    "new_checkpoint_path = \"/home/ir739wb/ilyarekun/nn_DeiT_25/cifar100_imagenet_style/teacher_regnety160_adapted.pth\"\n",
    "torch.save(checkpoint, new_checkpoint_path)\n",
    "print(f\"Адаптированная контрольная точка сохранена в: {new_checkpoint_path}\")\n",
    "\n",
    "# Проверка структуры нового state_dict\n",
    "print(\"\\nПервые 10 ключей в новом state_dict:\")\n",
    "for i, key in enumerate(new_state_dict.keys()):\n",
    "    if i < 10:\n",
    "        print(f\"  {key}\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
